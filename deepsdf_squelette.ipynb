{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import mcubes\n",
    "from torch import nn\n",
    "from scipy import spatial\n",
    "from matplotlib import pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms \n",
    "\n",
    "from PIL import Image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLuNet(nn.Module):\n",
    "    def __init__(self, ninputchannels):\n",
    "        super(ReLuNet, self).__init__()\n",
    "        #MLP with 8 layers\n",
    "        self.fc1 = nn.Linear(ninputchannels, 3)\n",
    "        self.fc2 = nn.Linear(3, 512)\n",
    "        self.fc3 = nn.Linear(512, 512)\n",
    "        self.fc4 = nn.Linear(512,509)\n",
    "        self.fc5 = nn.Linear(509,512)\n",
    "        self.fc6 = nn.Linear(512,512)\n",
    "        self.fc7 = nn.Linear(512,512)\n",
    "        self.fc8 = nn.Linear(512,1)\n",
    "\n",
    "        self.skip = nn.Linear(ninputchannels, 509)\n",
    "\n",
    "    def forward(self,x):\n",
    "        #TODO\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = torch.concat([x, F.relu(self.skip(x))], dim = 1)\n",
    "        x = F.relu(self.fc5(x))\n",
    "        x = F.relu(self.fc6(x))\n",
    "        x = F.relu(self.fc7(x))\n",
    "        x = F.tanh(self.fc8(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_loss(relunet, pts_gt, sdf_gt, device, lpc, batch_size=2000, delta = 0.1, pc_batch_size=2000):\n",
    "    #pts_random = torch.rand((batch_size, 3), device = device)*2-1\n",
    "    indices = torch.randint(pts_gt.shape[0], (batch_size,))\n",
    "    pts_gt_sub = pts_gt[indices,:]\n",
    "\n",
    "    #TODO: compute the result\n",
    "    output = relunet(pts_gt_sub).to(device)\n",
    "\n",
    "    # compute and store the losses\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    def clamp(x):\n",
    "        return torch.clamp(x, -delta, delta)\n",
    "    \n",
    "    loss = sum(abs(clamp(output) - clamp(sdf_gt[indices].view(-1,1))))\n",
    "\n",
    "    # append all the losses\n",
    "    lpc.append(float(loss.item()))\n",
    "  \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_shape() :\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    p = np.loadtxt('armadillo_sub.xyz')\n",
    "    \n",
    "    #compute the enclosing grid\n",
    "    maxx = np.max(p[:,0])\n",
    "    minx = np.min(p[:,0])\n",
    "    maxy = np.max(p[:,1])\n",
    "    miny = np.min(p[:,1])\n",
    "    maxz = np.max(p[:,2])\n",
    "    minz = np.min(p[:,2])\n",
    "    \n",
    "    #normalize the shape \n",
    "    maxdim = np.max((maxx-minx, maxy-miny, maxz-minz))\n",
    "    \n",
    "    p[:,0:3] = 1.9999*(p[:,0:3] - [minx,miny,minz])/maxdim-0.99999\n",
    "\n",
    "    #preparing gt points:\n",
    "    #TODO: using a kdtree find the groundtruth distance from the points to the shape\n",
    "    gtsdf = spatial.KDTree(p[:,0:3])\n",
    "    \n",
    "    geomnet = ReLuNet(3)\n",
    "    geomnet.to(device)\n",
    "\n",
    "    gtpoints = torch.from_numpy(gtp).float().to(device)\n",
    "    gtsdf = torch.from_numpy(sdf).float().to(device)\n",
    "\n",
    "    lpc = []\n",
    "\n",
    "    optim = torch.optim.Adam(params = geomnet.parameters(), lr=1e-5)\n",
    "\n",
    "    nepochs=10000\n",
    "    \n",
    "    for epoch in range(nepochs):\n",
    "        #TODO do one step training\n",
    "        optim.zero_grad()\n",
    "        output = geomnet(gtpoints)\n",
    "        loss = evaluate_loss(geomnet, gtpoints, gtsdf, device, lpc)\n",
    "        loss.backward()\n",
    "        lpc.append(loss.item())\n",
    "        optim.step()\n",
    "        if epoch % 100 == 0:\n",
    "            print(f\"Epoch {epoch}/{nepochs} - loss : {loss.item()}\")\n",
    "\n",
    "    #use marching cubes to extract the shape\n",
    "    \n",
    "\n",
    "    # display the result\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.yscale('log')\n",
    "    plt.plot(lpc, label = 'Point cloud loss ({:.2f})'.format(lpc[-1]))\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.legend()\n",
    "    plt.savefig(\"loss.pdf\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_shape()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some explanation\n",
    "\n",
    "**DeepSDF** (Deep Signed Distance Function) is a neural network-based approach for representing and reconstructing 3D shapes. It leverages the concept of Signed Distance Functions (SDFs) to model the surface of 3D objects. DeepSDF was introduced by Park et al. in their 2019 paper \"DeepSDF: Learning Continuous Signed Distance Functions for Shape Representation.\"\n",
    "\n",
    "### Key Concepts\n",
    "\n",
    "1. **Signed Distance Function (SDF)**:\n",
    "   - An SDF is a scalar field that represents the distance from any point in space to the closest surface of an object.\n",
    "   - The distance is positive if the point is outside the object, negative if the point is inside, and zero if the point is on the surface.\n",
    "\n",
    "2. **Neural Network Representation**:\n",
    "   - DeepSDF uses a neural network to parameterize the SDF.\n",
    "   - The network takes a 3D coordinate as input and outputs the signed distance value for that coordinate.\n",
    "\n",
    "3. **Continuous Representation**:\n",
    "   - Unlike voxel grids or point clouds, DeepSDF provides a continuous representation of 3D shapes, allowing for high-resolution and smooth surfaces.\n",
    "\n",
    "### How DeepSDF Works\n",
    "\n",
    "1. **Network Architecture**:\n",
    "   - The DeepSDF network is typically a multi-layer perceptron (MLP) with several fully connected layers.\n",
    "   - The input to the network is a 3D coordinate (x, y, z), and the output is the signed distance value for that coordinate.\n",
    "\n",
    "2. **Training**:\n",
    "   - The network is trained using a dataset of 3D shapes, where each shape is represented by a set of 3D coordinates and their corresponding signed distance values.\n",
    "   - The loss function is typically the mean squared error (MSE) between the predicted signed distance values and the ground truth values.\n",
    "\n",
    "3. **Shape Representation**:\n",
    "   - Once trained, the network can represent a variety of 3D shapes by encoding them as continuous SDFs.\n",
    "   - The network can be queried at any 3D coordinate to obtain the signed distance value, allowing for high-resolution surface reconstruction.\n",
    "\n",
    "4. **Latent Code**:\n",
    "   - DeepSDF can also incorporate a latent code to represent different shapes in a latent space.\n",
    "   - The latent code is concatenated with the 3D coordinates and fed into the network, enabling the network to learn a continuous family of shapes.\n",
    "\n",
    "### Example Code\n",
    "\n",
    "Here is a simplified example of how to implement a DeepSDF-like network in PyTorch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class DeepSDF(nn.Module):\n",
    "    def __init__(self, latent_dim=256):\n",
    "        super(DeepSDF, self).__init__()\n",
    "        self.fc1 = nn.Linear(3 + latent_dim, 512)\n",
    "        self.fc2 = nn.Linear(512, 512)\n",
    "        self.fc3 = nn.Linear(512, 512)\n",
    "        self.fc4 = nn.Linear(512, 512)\n",
    "        self.fc5 = nn.Linear(512, 1)\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "    def forward(self, x, latent_code):\n",
    "        x = torch.cat([x, latent_code], dim=-1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        sdf = self.fc5(x)\n",
    "        return sdf\n",
    "\n",
    "# Example usage\n",
    "latent_dim = 256\n",
    "model = DeepSDF(latent_dim=latent_dim)\n",
    "\n",
    "# Example input: 3D coordinates and latent code\n",
    "coords = torch.randn(10, 3)  # 10 points in 3D space\n",
    "latent_code = torch.randn(10, latent_dim)  # Corresponding latent code\n",
    "\n",
    "# Forward pass\n",
    "sdf_values = model(coords, latent_code)\n",
    "print(sdf_values.shape)  # Should be (10, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Points\n",
    "\n",
    "- **DeepSDF**: A neural network-based approach for representing and reconstructing 3D shapes using Signed Distance Functions.\n",
    "- **SDF**: Represents the distance from any point in space to the closest surface of an object, with the sign indicating whether the point is inside or outside the object.\n",
    "- **Continuous Representation**: Provides a high-resolution and smooth representation of 3D shapes.\n",
    "- **Latent Code**: Allows the network to learn a continuous family of shapes by incorporating a latent code."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
